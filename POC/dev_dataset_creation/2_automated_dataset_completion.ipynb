{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Run this notebook after manully populating the dev dataset with the help of the notebook 1_curated_dataset_creation.ipynb to complement the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "from fasttext.FastText import _FastText\n",
    "import pandas as pd\n",
    "\n",
    "from automated_dataset_completion_helpers import extract_html_plain_text, extract_gdpr_plain_text_if_gdpr_website, fasttext_language_predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load config for dev dataset creation process\n",
    "config_file = open(f\"{str(Path.cwd())}/dev_dataset_creation_config.json\")\n",
    "config = json.load(config_file)\n",
    "config_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get plain text from HTMLs in each subfolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "subfolder_names = sorted([int(x[0].replace(f\"{config['dev_dataset_path']}/\", \"\")) for x in list(os.walk(config['dev_dataset_path']))[1:]])\n",
    "\n",
    "for sample_index in subfolder_names:\n",
    "    sample_dir_path = f\"{config['dev_dataset_path']}/{sample_index}\"\n",
    "\n",
    "    extract_html_plain_text(sample_dir_path)\n",
    "\n",
    "    extract_gdpr_plain_text_if_gdpr_website(sample_dir_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detect Languages\n",
    "For the extracted text of each website determine its language.\n",
    "- In order to use TI-IDF method, which is based on a vocabulary, we need to handle german and english websites separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ft_model = _FastText(model_path=\"./pretrained_language_detection_model/lid.176.bin\")\n",
    "\n",
    "languages = []\n",
    "\n",
    "for sample_index in subfolder_names:\n",
    "    sample_dir_path = f\"{config['dev_dataset_path']}/{sample_index}\"\n",
    "    content_text_path = f\"{sample_dir_path}/content.txt\"\n",
    "    with open(content_text_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "        language_label = fasttext_language_predict(content, ft_model)\n",
    "        languages.append(language_label[0][0][0])\n",
    "\n",
    "languages_df = pd.DataFrame(languages)\n",
    "languages_df.to_json(f\"{config['dev_dataset_path']}/dev_dataset_languages.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add URLs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load tabel of all seed websites\n",
    "file = pd.ExcelFile(f\"{config['input_data_path']}/companies_enc.xlsx\")\n",
    "seeds_df = pd.read_excel(file, 'Companies')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "urls_of_dev_dateset = []\n",
    "\n",
    "for sample_index in subfolder_names:\n",
    "    url = seeds_df.loc[int(sample_index)]['url']\n",
    "    urls_of_dev_dateset.append(url)\n",
    "\n",
    "dev_dataset_urls_df = pd.DataFrame(urls_of_dev_dateset)\n",
    "dev_dataset_urls_df.to_json(f\"{config['dev_dataset_path']}/dev_dataset_urls.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the dev_dataset is complete and can be accessed with the GDPRDataset pytorch Dataset class."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
